
import { geminiModel } from "./geminiClient";


interface ImageAnalysisResult {
  valid: boolean;
  reason?: string; // If invalid (NSFW, Not a vehicle)
  category?: string; // 'automovil', 'motocicleta', 'comercial', 'industrial', 'transporte', 'especial'
  invalidIndices?: number[]; // üö® NEW: Indices of images that are NOT vehicles
  details?: {
    // Identificaci√≥n b√°sica
    brand?: string;
    model?: string;
    year?: string; // Estimated
    color?: string;
    type?: string; // SUV, Sedan, Pickup, etc.

    // Caracter√≠sticas t√©cnicas
    transmission?: string; // Manual, Autom√°tica, CVT
    fuel?: string; // Gasolina, Di√©sel, El√©ctrico, H√≠brido
    engine?: string; // Ej: "2.0L Turbo", "V6 3.5L"
    doors?: number; // 2, 4, 5
    mileage?: number; // Kilometraje estimado si es visible
    condition?: string; // Nuevo, Seminuevo, Usado

    // Caracter√≠sticas visibles (para vender el veh√≠culo)
    features?: string[]; // ["Quemacocos", "Rines aleaci√≥n", "C√°mara reversa", etc.]

    // Campos espec√≠ficos por tipo de veh√≠culo
    displacement?: number; // Cilindrada en cc (motos)
    cargoCapacity?: number; // Toneladas (camiones)
    operatingHours?: number; // Horas de uso (maquinaria)
  };
}

export async function analyzeImage(imageBase64: string, type: 'VEHICLE' | 'BUSINESS' = 'VEHICLE'): Promise<ImageAnalysisResult> {
  console.log(`ü§ñ Analizando imagen (${type}) con Gemini Vision...`);

  let prompt = '';

  if (type === 'BUSINESS') {
    // üü¢ RELAXED VALIDATION FOR BUSINESS
    prompt = `
ERES UN MODERADOR DE CONTENIDO PARA UNA RED SOCIAL DE NEGOCIOS.
TU TRABAJO ES FILTRAR SOLO EL CONTENIDO PELIGROSO O ILEGAL.

‚úÖ PERMITIDO (TODO LO QUE NO EST√â PROHIBIDO):
- Logos, Fachadas, Tarjetas de presentaci√≥n
- Personas (mec√°nicos, clientes, staff)
- Memes, Humor, Publicidad, Flyers
- Veh√≠culos, Herramientas, Talleres
- CUALQUIER imagen segura para el trabajo (SFW)

‚ùå PROHIBIDO ESTRICTAMENTE (TOLERANCIA CERO):
- üîû CONTENIDO SEXUAL EXPL√çCITO (Desnudos, pornograf√≠a, poses lascivas)
- ü©∏ VIOLENCIA EXTREMA (Sangre real, gore, accidentes fatales, tortura)
- üî´ ARMAS REALES en contexto violento (no herramientas)
- üíä DROGAS ILEGALES o parafernalia expl√≠cita
- üñï DISCURSO DE ODIO (S√≠mbolos nazis, racistas, etc.)

SI LA IMAGEN ES SEGURA (Aunque sea un meme o un dibujo):
Responde {"valid": true}

SI LA IMAGEN VIOLA LAS REGLAS:
Responde {"valid": false, "reason": "Explicaci√≥n breve en espa√±ol"}

RESPONDE SOLO EL JSON.
`;
  } else {
    // üöó VALIDATION FOR VEHICLES
    prompt = `
ERES UN MODERADOR INTELIGENTE Y PROTECTOR PARA CARMATCH.
TU MISI√ìN: Asegurar que las im√°genes sean PARTES/VEH√çCULOS reales y, sobre todo, SEGURAS PARA TODA LA FAMILIA (incluyendo menores).

‚ïê‚ïê‚ïê CRITERIOS DE APROBACI√ìN (SFW - SEGURO) ‚ïê‚ïê‚ïê
‚úÖ ACEPTA:
- Veh√≠culos reales completos o piezas mec√°nicas (Motores, chasis, llantas, rines, transmisiones).
- Fotos con texto de venta o capturas de buena calidad.

‚ïê‚ïê‚ïê CRITERIOS DE RECHAZO ABSOLUTO (TOLERANCIA CERO) ‚ïê‚ïê‚ïê
üö´ RECHAZA INMEDIATAMENTE:
- üîû CONTENIDO ADULTO: Desnudez, poses lascivas o ropa sugerente. La app es para ni√±os y j√≥venes tambi√©n.
- ü©∏ VIOLENCIA: Sangre, accidentes reales grotescos, gore o armas.
- üñï CONTENIDO OFENSIVO: Odio, racismo o lenguaje vulgar.
- üß∏ JUGUETES o maquetas.
- üì∫ FOTOS A PANTALLAS.
- üë• IRRELEVANTE: Memes, animales, comida o personas como protagonistas.
- üìÖ FLEXIBILIDAD TOTAL EN A√ëOS: Muchos veh√≠culos permanecen visualmente ID√âNTICOS por periodos de 5 a 10 a√±os (mismas generaciones). No rechaces por error de a√±o si la marca, modelo y generaci√≥n visual coinciden. S√© muy flexible: el a√±o es informativo, no un criterio de exclusi√≥n a menos que sea f√≠sicamente imposible (ej: un carro moderno marcado como 1950).

RESPONDE √öNICAMENTE CON ESTE JSON:
{
  "valid": boolean,
  "reason": "Explicaci√≥n breve (en Espa√±ol)",
  "category": "automovil" | "motocicleta" | "comercial" | "industrial" | "transporte" | "especial" | null,
  "details": {
    "brand": "Marca",
    "model": "Modelo",
    "year": "A√±o estimado",
    "color": "Color",
    "type": "SUV|Sedan|Pickup|etc"
  }
}
`;
  }

  try {
    const imagePart = {
      inlineData: {
        data: imageBase64,
        mimeType: "image/jpeg",
      },
    };

    const result = await geminiModel.generateContent([prompt, imagePart]);
    const response = await result.response;
    const text = response.text();

    console.log("ü§ñ Respuesta Raw Gemini:", text);

    const firstBrace = text.indexOf('{');
    const lastBrace = text.lastIndexOf('}');
    if (firstBrace === -1 || lastBrace === -1) throw new Error("No JSON found");
    const jsonString = text.substring(firstBrace, lastBrace + 1);

    try {
      return JSON.parse(jsonString);
    } catch (parseError) {
      console.error("‚ùå Error parseando JSON de Gemini:", parseError, "Texto recibido:", text);
      return { valid: false, reason: "Error de validaci√≥n t√©cnica. Intenta con otra foto." };
    }

  } catch (error) {
    console.error("‚ùå Error CR√çTICO en an√°lisis de imagen:", error);
    return { valid: false, reason: "El servicio de seguridad no est√° disponible. Reintenta en un momento." };
  }
}

/**
 * Analiza M√öLTIPLES im√°genes para obtener datos consolidados
 * @param images Array de im√°genes en base64
 * @param type Tipo de publicaci√≥n ('VEHICLE' | 'BUSINESS')
 * @returns An√°lisis consolidado
 */
export async function analyzeMultipleImages(
  images: string[],
  type: 'VEHICLE' | 'BUSINESS' = 'VEHICLE',
  context?: { brand?: string, model?: string, year?: string }
): Promise<ImageAnalysisResult> {
  console.log(`ü§ñ AI Contextual: Analizando ${images.length} im√°genes...`);

  const vehicleContextPrompt = context?.brand
    ? `\nGU√çA DE CONTEXTO: El usuario dice tener un ${context.brand} ${context.model || ''} ${context.year || ''}.
       Usa esto para ayudarte a identificar si es un veh√≠culo real, pero s√© FLEXIBLE.
       Si el usuario se equivoca de a√±o o modelo pero sube un carro real, ¬°APRU√âBALO! (Puede ser error humano).`
    : '';

  const prompt = type === 'VEHICLE'
    ? `ERES UN EXPERTO ANALISTA DE VEH√çCULOS PARA CARMATCH.
       TU √öNICO OBJETIVO: Confirmar que las fotos sean de veh√≠culos reales y seguros.

       üìã DATOS PROPORCIONADOS POR USUARIO (SOLO REFERENCIA):
       - Marca: "${context?.brand || '?'}"
       - Modelo: "${context?.model || '?'}"
       - A√±o: "${context?.year || '?'}"
       
       ‚ö†Ô∏è REGLA DE ORO: LA IMAGEN ES LA VERDAD ABSOLUTA.
       - Si la foto muestra un veh√≠culo real, APRU√âBALO (isValid: true).
       - IGNORA si la marca/modelo del texto no coinciden con la foto. (Ej: Texto dice "Abarth" pero foto es "Hyundai" -> APROBAR y corregir en "details").
       - SOLO RECHAZA si NO es un veh√≠culo o es contenido inseguro.

       üîç VALIDACI√ìN DE GALER√çA (COHERENCIA):
       - Imagen 0 (Portada) define el veh√≠culo.
       - Im√°genes 1..N deben ser del MISMO veh√≠culo (mismo color/modelo).
       - Si una imagen de galer√≠a es de OTRO carro diferente al de la portada -> MARCAR COMO INV√ÅLIDA (isValid: false).

       üö´ MOTIVOS DE RECHAZO:
       - No es un veh√≠culo (Paisajes vac√≠os, comida, selfies, mascotas).
       - Juguetes, maquetas, capturas de pantalla, fotos a monitores.
       - NSFW, Gore, Violencia.

       Responde √öNICAMENTE este JSON (sin markdown):
       {
         "isValidCover": boolean,
         "coverReason": "Raz√≥n breve si es false",
         "analysis": [
           { "index": number, "isValid": boolean, "reason": "Raz√≥n si es false" }
         ],
         "details": {
           "brand": "Marca EXACTA que ves", 
           "model": "Modelo EXACTO que ves", 
           "year": "A√±o estimado", 
           "color": "Color", 
           "type": "SUV|Sedan|Pickup|Coupe|Hatchback|Van|Moto|Camion"
         }
       }`
    : `ERES UN MODERADOR DE CONTENIDO PARA PERFILES DE NEGOCIO.
       TU MISI√ìN: Permitir libertad creativa total, FILTRANDO SOLO CONTENIDO ILEGAL O PELIGROSO.
       
       ‚úÖ APRUEBA TODO ESTO (Ejemplos):
       - Memes, Logotipos, Carteles.
       - Fotos de personas, selfies, manos, pies.
       - Objetos random (sacapuntas, herramientas, comida).
       - Edificios, calles, mapas.
       - CUALQUIER IMAGEN que no viole las reglas de abajo.

       üö´ SOLO RECHAZA (isValid: false):
       - Pornograf√≠a expl√≠cita o desnudez total.
       - Violencia extrema, gore, sangre real.
       - Contenido de odio o s√≠mbolos terroristas.

       Si es una foto "rara" o "fea" pero segura -> APRU√âBALA.

       Responde √öNICAMENTE este JSON (sin markdown):
       {
         "isValidCover": boolean,
         "coverReason": "OK" o raz√≥n breve de rechazo,
         "analysis": [
           { "index": number, "isValid": boolean, "reason": "OK" }
         ],
         "details": { "category": "negotioc" }
       }`;

  try {
    const imageParts = images.map(img => ({
      inlineData: { data: img, mimeType: "image/jpeg" }
    }));

    // Fix: Analizar hasta 10 im√°genes (Portada + 9 Galer√≠a)
    const imagesToAnalyze = imageParts.slice(0, 10);

    const result = await geminiModel.generateContent([prompt, ...imagesToAnalyze]);
    const response = await result.response;

    if (response.promptFeedback?.blockReason) {
      return {
        valid: false,
        reason: "Bloqueado por seguridad.",
        invalidIndices: [0]
      };
    }

    const text = response.text();
    const match = text.match(/\{[\s\S]*\}/);
    if (!match) throw new Error("No JSON found");

    const parsed = JSON.parse(match[0]);

    const invalidIndices = (parsed.analysis || [])
      .filter((a: any) => a.isValid === false)
      .map((a: any) => Number(a.index));

    return {
      valid: parsed.isValidCover === true,
      reason: parsed.coverReason,
      invalidIndices: invalidIndices,
      details: parsed.details || {},
      category: 'automovil'
    };

  } catch (error: any) {
    console.error("‚ùå Error cr√≠tico en validaci√≥n de imagen:", {
      message: error.message,
      stack: error.stack,
      timestamp: new Date().toISOString()
    });

    if (error.message?.includes('SAFETY') || error.message?.includes('blocked')) {
      return { valid: false, reason: "Contenido bloqueado por seguridad.", invalidIndices: [0] };
    }

    // üõ°Ô∏è FAIL-SAFE: Rechazar por defecto si hay error
    // Esto previene que im√°genes inv√°lidas pasen cuando la IA falla
    return {
      valid: false,
      reason: "No pudimos verificar tu imagen. Por favor, intenta nuevamente.",
      invalidIndices: [0]
    };
  }
}
